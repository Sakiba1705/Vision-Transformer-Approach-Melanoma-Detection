{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmXNVrtM+zz4+zj8sONuOG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sakiba1705/CLIP-Vision-Transformer-Approach-Melanoma-Detection/blob/main/Melanoma_skin_cancer_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import vit_keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "YMTZVQ8V43p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define data paths"
      ],
      "metadata": {
        "id": "1_7YpTnL7L5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = 'train'\n",
        "validation_data_dir = 'validation'\n",
        "test_data_dir = 'test'"
      ],
      "metadata": {
        "id": "Re6Tj_Uy7xhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define parameters\n",
        " "
      ],
      "metadata": {
        "id": "phX4CcRd8CrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "NUM_CLASSES = 2"
      ],
      "metadata": {
        "id": "Wi_tqZFP8Fjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define data augmentation"
      ],
      "metadata": {
        "id": "QzrRuOcP9Jhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "WVtsQojg9dVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define data generators"
      ],
      "metadata": {
        "id": "H11ZESlX94Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "b-zflpFS98qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade vit-keras"
      ],
      "metadata": {
        "id": "OEeL8yblNVDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build ViT model"
      ],
      "metadata": {
        "id": "njKX2NrU-gMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vit_model():\n",
        "    inputs = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "    vit_model = vit_keras.vit.Vit(\n",
        "        include_top=False,\n",
        "        input_tensor=inputs,\n",
        "        classes=NUM_CLASSES\n",
        "    )\n",
        "    x = layers.Flatten()(vit_model(inputs))\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "    return tf.keras.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "DetQEWTO-krs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call build_vit_model() to create the model"
      ],
      "metadata": {
        "id": "prX7y2GEIB9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vit_model = build_vit_model()\n"
      ],
      "metadata": {
        "id": "3Q2rhZAhIGOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile and train the model"
      ],
      "metadata": {
        "id": "FlsFnQoR-2my"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vit_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = vit_model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator\n",
        ")"
      ],
      "metadata": {
        "id": "KpdkJZU6-92P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model\n",
        " "
      ],
      "metadata": {
        "id": "NR_1UJp1EqtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = vit_model.evaluate(test_generator)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "UiNznGycExea"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}